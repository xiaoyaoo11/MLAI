{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11074658,"sourceType":"datasetVersion","datasetId":6901910}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport pathlib\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntraining_dir = pathlib.Path('/kaggle/input/radar-signal-classification/training_set')\n\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\nfull_dataset = datasets.ImageFolder(root=str(training_dir), transform=transform)\n\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\nclass_names = full_dataset.classes  \nnum_classes = len(class_names)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n\nprint(f\"Classes: {class_names}\")\nprint(f\"Training samples: {train_size}, Validation samples: {val_size}\")\n\n\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes=8):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        \n        self.batchnorm1 = nn.BatchNorm2d(32)\n        self.batchnorm2 = nn.BatchNorm2d(64)\n        self.batchnorm3 = nn.BatchNorm2d(128)\n        \n        self.pool = nn.MaxPool2d(2, 2)  \n        \n        self.fc1 = nn.Linear(128 * 16 * 16, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n\n        self.dropout = nn.Dropout(0.3)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.batchnorm1(self.conv1(x))))  \n        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))  \n        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))  \n\n        x = x.view(x.size(0), -1)  \n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n\n        return F.log_softmax(x, dim=1)\n\n\nmodel = SimpleCNN(num_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ndef train(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss, correct, total = 0.0, 0, 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n        \n        train_loss.append(running_loss / len(train_loader))\n        train_acc.append(correct / total)\n\n        model.eval()\n        val_running_loss, correct, total = 0.0, 0, 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_running_loss += loss.item()\n\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n\n        val_loss.append(val_running_loss / len(val_loader))\n        val_acc.append(correct / total)\n\n        print(f\"Epoch {epoch+1}/{epochs} - \"\n              f\"Train Loss: {train_loss[-1]:.4f}, Train Acc: {train_acc[-1]:.4f} - \"\n              f\"Val Loss: {val_loss[-1]:.4f}, Val Acc: {val_acc[-1]:.4f}\")\n\n    return model\n\n\nepochs = 5\nmodel = train(model, train_loader, val_loader, criterion, optimizer, epochs)\nexample_input = torch.randn(1, 3, 128, 128).to(device)  \ntraced_model = torch.jit.trace(model, example_input)\n\n# sinh vien luu model voi name la mssv\ntraced_model.save(\"22111001.pt\")\nprint(\"Model saved as 22111001.pt\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-31T04:55:03.482583Z","iopub.execute_input":"2025-03-31T04:55:03.483014Z","iopub.status.idle":"2025-03-31T04:56:38.862516Z","shell.execute_reply.started":"2025-03-31T04:55:03.482975Z","shell.execute_reply":"2025-03-31T04:56:38.861779Z"}},"outputs":[{"name":"stdout","text":"Classes: ['B-FM', 'Barker', 'CPFSK', 'DSB-AM', 'GFSK', 'LFM', 'Rect', 'SSB-AM']\nTraining samples: 5120, Validation samples: 1280\nEpoch 1/5 - Train Loss: 1.5230, Train Acc: 0.5594 - Val Loss: 0.5625, Val Acc: 0.7742\nEpoch 2/5 - Train Loss: 0.6030, Train Acc: 0.7324 - Val Loss: 0.4669, Val Acc: 0.7961\nEpoch 3/5 - Train Loss: 0.5175, Train Acc: 0.7533 - Val Loss: 0.5442, Val Acc: 0.7211\nEpoch 4/5 - Train Loss: 0.4552, Train Acc: 0.7824 - Val Loss: 0.3687, Val Acc: 0.8102\nEpoch 5/5 - Train Loss: 0.4014, Train Acc: 0.8094 - Val Loss: 0.3726, Val Acc: 0.8211\nModel saved as 22111001.pt\n","output_type":"stream"}],"execution_count":1}]}